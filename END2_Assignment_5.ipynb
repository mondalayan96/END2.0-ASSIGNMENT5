{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2_Assignment_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY4eAjHGbFON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ccadf2-b793-4dca-c8dd-e3cf6e2e888f"
      },
      "source": [
        "!pip install pytreebank\n",
        "import pytreebank\n",
        "import sys\n",
        "import os\n",
        "\n",
        "out_path = os.path.join(sys.path[0], 'sst_{}.csv')\n",
        "dataset = pytreebank.load_sst('./raw_data')\n",
        "\n",
        "# Store train, dev and test in separate files\n",
        "for category in ['train', 'test', 'dev']:\n",
        "    with open(out_path.format(category), 'w') as outfile:\n",
        "        for item in dataset[category]:\n",
        "            outfile.write(\"{}\\t{}\\n\".format(\n",
        "                item.to_labeled_lines()[0][0] + 1,\n",
        "                item.to_labeled_lines()[0][1]\n",
        "            ))\n",
        "# Print the length of the training set\n",
        "print(len(dataset['train']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytreebank\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n",
            "Building wheels for collected packages: pytreebank\n",
            "  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp37-none-any.whl size=37070 sha256=a0bd94c3f807d9d262a78d99f331c676621b3fec46680162079cd050006aa463\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n",
            "Successfully built pytreebank\n",
            "Installing collected packages: pytreebank\n",
            "Successfully installed pytreebank-0.2.7\n",
            "8544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb9yKw7F86R-"
      },
      "source": [
        "import pandas as pd\n",
        "df_dev = pd.read_csv(\"sst_dev.csv\",delimiter=\"\\t\",names = [\"label\",\"text\"])\n",
        "df_dev.to_csv(\"sst_dev.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlzP22Uv9v8J"
      },
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv(\"sst_test.csv\",delimiter=\"\\t\",names = [\"label\",\"text\"])\n",
        "df_test.to_csv(\"sst_test.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "rE-ylf6C6BJD",
        "outputId": "dd4fd350-d49b-4808-b6d5-8a1b6842a224"
      },
      "source": [
        "#Train data\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"sst_train.csv\",delimiter=\"\\t\",names = [\"label\",\"text\"])\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Whether or not you 're enlightened by any of D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>Just the labour involved in creating the layer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>Part of the charm of Satin Rouge is that it av...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>a screenplay more ingeniously constructed than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>`` Extreme Ops '' exceeds expectations .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      4  The Rock is destined to be the 21st Century 's...\n",
              "1      5  The gorgeously elaborate continuation of `` Th...\n",
              "2      4  Singer/composer Bryan Adams contributes a slew...\n",
              "3      3  You 'd think by now America would have had eno...\n",
              "4      4               Yet the act is still charming here .\n",
              "5      5  Whether or not you 're enlightened by any of D...\n",
              "6      5  Just the labour involved in creating the layer...\n",
              "7      4  Part of the charm of Satin Rouge is that it av...\n",
              "8      5  a screenplay more ingeniously constructed than...\n",
              "9      4           `` Extreme Ops '' exceeds expectations ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ubRjtD6i99Aw",
        "outputId": "0429743e-2c5b-4305-896b-aeb71125da87"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "ax = df['label'].value_counts(sort=False).plot(kind='barh')\n",
        "ax.set_xlabel(\"Number of Samples in training Set\")\n",
        "ax.set_ylabel(\"Label\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOKzC1rvKt_i"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "!pip install -q google_trans_new \n",
        "from google_trans_new import google_translator\n",
        "\n",
        "def back_translate(sequence, PROB = 1):\n",
        "    languages = ['en','fr','tr'] #'ur', 'ru', 'bg', 'de', 'ar', 'zh-cn', 'hi','sw', 'vi', 'es', 'el']\n",
        "    \n",
        "    #instantiate translator\n",
        "    translator = google_translator()\n",
        "    \n",
        "    #store original language so we can convert back\n",
        "    org_lang = 'en'\n",
        "    \n",
        "    #randomly choose language to translate sequence to  \n",
        "    random_lang = np.random.choice([lang for lang in languages if lang is not org_lang])\n",
        "    \n",
        "    if org_lang in languages:\n",
        "        #translate to new language and back to original\n",
        "        translated = translator.translate(sequence, lang_tgt = random_lang)\n",
        "        #translate back to original language\n",
        "        translated_back = translator.translate(translated, lang_tgt = org_lang)\n",
        "        output_sequence = translated_back\n",
        "            \n",
        "    #if detected language not in our list of languages, do nothing\n",
        "    else:\n",
        "        output_sequence = sequence\n",
        "    \n",
        "    return output_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5YZ-8Wu0Bt4"
      },
      "source": [
        "#df[\"New_text\"] = df.apply(lambda x: (back_translate(x[\"text\"])),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKftI7AyDkUH"
      },
      "source": [
        "# #Creating augmented data - for every sample 3 more data sample are augmented\n",
        "# import timeit\n",
        "\n",
        "# start = timeit.default_timer()\n",
        "# df_augmented = pd.DataFrame()\n",
        "# li = []\n",
        "# l = []\n",
        "# for j in range(0,len(df)+1):\n",
        "#   output = back_translate(df.text[j])\n",
        "#   li.append(output)\n",
        "#   l.append(df.label[j])\n",
        "#   if j%200 == 0:\n",
        "#     print(j)\n",
        "\n",
        "# df_augmented = pd.DataFrame(list(zip(l,li)),\n",
        "#                columns =['label', 'text'])\n",
        "\n",
        "# #sample1.reset_index(inplace=True)\n",
        "# print(df_augmented.head())\n",
        "\n",
        "# stop = timeit.default_timer()\n",
        "# print('Time: ', stop - start)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMVNkxjszbuj"
      },
      "source": [
        "def random_deletion(words, p=0.2):\n",
        "\n",
        "    words = words.split()\n",
        "    \n",
        "    #obviously, if there's only one word, don't delete it\n",
        "    if len(words) == 1 :\n",
        "        return words\n",
        "\n",
        "    #randomly delete words with probability p\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        r = random.uniform(0, 1)\n",
        "        if r > p:\n",
        "            new_words.append(word)\n",
        "\n",
        "    #if you end up deleting all words, just return a random word\n",
        "    if len(new_words) == 0:\n",
        "        rand_int = random.randint(0, len(words)-1)\n",
        "        return [words[rand_int]]\n",
        "\n",
        "    sentence = ' '.join(new_words)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3vBxhZ1q6stq",
        "outputId": "3c0889ee-ceed-4d51-e3db-13104b47c2dc"
      },
      "source": [
        "s = \"The Rock is destined to be the 21st Century\"\n",
        "random_deletion(s, p=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The Rock is destined be the 21st Century'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PhzAbVm5VKM"
      },
      "source": [
        "df[\"New_text_del\"] = df.apply(lambda x: random_deletion(x[\"text\"],0.2) , axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "pTXWMG365bCc",
        "outputId": "db101b0a-347d-43c1-f3f5-20911007b54c"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>New_text_del</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>The Rock destined be the 21st 's new Conan and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>gorgeously elaborate continuation of `` The Lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
              "      <td>Singer/composer Adams contributes slew songs f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "      <td>You by now America would have had enough of pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "      <td>Yet the still charming here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8539</th>\n",
              "      <td>1</td>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>A real snooze .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8540</th>\n",
              "      <td>2</td>\n",
              "      <td>No surprises .</td>\n",
              "      <td>No surprises .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8541</th>\n",
              "      <td>4</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8542</th>\n",
              "      <td>1</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8543</th>\n",
              "      <td>2</td>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>In this case zero .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8544 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  ...                                       New_text_del\n",
              "0         4  ...  The Rock destined be the 21st 's new Conan and...\n",
              "1         5  ...  gorgeously elaborate continuation of `` The Lo...\n",
              "2         4  ...  Singer/composer Adams contributes slew songs f...\n",
              "3         3  ...  You by now America would have had enough of pl...\n",
              "4         4  ...                        Yet the still charming here\n",
              "...     ...  ...                                                ...\n",
              "8539      1  ...                                    A real snooze .\n",
              "8540      2  ...                                     No surprises .\n",
              "8541      4  ...  We 've seen the hippie-turned-yuppie plot befo...\n",
              "8542      1  ...  Her fans walked out muttering words like `` ho...\n",
              "8543      2  ...                                In this case zero .\n",
              "\n",
              "[8544 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWwLPXGubmYB"
      },
      "source": [
        "def swap_word(new_words):\n",
        "    \n",
        "    random_idx_1 = random.randint(0, len(new_words)-1)\n",
        "    random_idx_2 = random_idx_1\n",
        "    counter = 0\n",
        "    \n",
        "    while random_idx_2 == random_idx_1:\n",
        "        random_idx_2 = random.randint(0, len(new_words)-1)\n",
        "        counter += 1\n",
        "        \n",
        "        if counter > 3:\n",
        "            return new_words\n",
        "    \n",
        "    new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1] \n",
        "    return new_words\n",
        "\n",
        "def random_swap(words, n):\n",
        "    \n",
        "    words = words.split()\n",
        "    new_words = words.copy()\n",
        "    \n",
        "    for _ in range(n):\n",
        "        new_words = swap_word(new_words)\n",
        "        \n",
        "    sentence = ' '.join(new_words)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qS5iLlDubr1Y",
        "outputId": "d41835c9-6a2c-41dd-ecb9-2e6d8be33e99"
      },
      "source": [
        "s = \"The Rock is destined to be the 21st Century\"\n",
        "random_swap(s, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The Rock is destined to be Century 21st the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF89Dxxtbx-K"
      },
      "source": [
        "df[\"New_text_swap\"] = df.apply(lambda x: random_swap(x[\"text\"],2) , axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "whZ_aP2ab7W1",
        "outputId": "264d9afa-abdd-491f-a275-e9f0e4ffb088"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>New_text_del</th>\n",
              "      <th>New_text_swap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>The Rock destined be the 21st 's new Conan and...</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>gorgeously elaborate continuation of `` The Lo...</td>\n",
              "      <td>The huge elaborate continuation of that The Lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
              "      <td>Singer/composer Adams contributes slew songs f...</td>\n",
              "      <td>few Bryan Adams contributes a slew of songs --...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "      <td>You by now America would have had enough of pl...</td>\n",
              "      <td>You with British by now America would have had...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "      <td>Yet the still charming here</td>\n",
              "      <td>Yet the here is still act charming .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8539</th>\n",
              "      <td>1</td>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>real snooze A .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8540</th>\n",
              "      <td>2</td>\n",
              "      <td>No surprises .</td>\n",
              "      <td>No surprises .</td>\n",
              "      <td>No surprises .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8541</th>\n",
              "      <td>4</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8542</th>\n",
              "      <td>1</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>but fans walked out muttering words like `` ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8543</th>\n",
              "      <td>2</td>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>In zero case . this</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8544 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  ...                                      New_text_swap\n",
              "0         4  ...  The Rock is destined to be the 21st Century 's...\n",
              "1         5  ...  The huge elaborate continuation of that The Lo...\n",
              "2         4  ...  few Bryan Adams contributes a slew of songs --...\n",
              "3         3  ...  You with British by now America would have had...\n",
              "4         4  ...               Yet the here is still act charming .\n",
              "...     ...  ...                                                ...\n",
              "8539      1  ...                                    real snooze A .\n",
              "8540      2  ...                                     No surprises .\n",
              "8541      4  ...  We 've seen the hippie-turned-yuppie plot befo...\n",
              "8542      1  ...  but fans walked out muttering words like `` ho...\n",
              "8543      2  ...                                In zero case . this\n",
              "\n",
              "[8544 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crReEeNZc3mT"
      },
      "source": [
        "df1_del = df[[\"label\",\"New_text_del\"]]\n",
        "df1_del = df1_del.rename(columns={\"New_text_del\": \"text\"})\n",
        "df1_swap = df[[\"label\",\"New_text_swap\"]]\n",
        "df1_swap = df1_swap.rename(columns={\"New_text_swap\": \"text\"})\n",
        "df_combined = pd.concat([df1_del,df1_swap],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZtsfxBYdodK",
        "outputId": "c39d3d30-5a13-4e6f-dfe1-1eab20bae417"
      },
      "source": [
        "df_combined.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17088, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48_wpoJLdhJR"
      },
      "source": [
        "df_final = df[[\"label\",\"text\"]]\n",
        "df_final = pd.concat([df_final,df_combined],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "TiWUtXSSd1Do",
        "outputId": "f15d9a81-079f-42b3-e1f6-3b55cd853224"
      },
      "source": [
        "df_final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8539</th>\n",
              "      <td>1</td>\n",
              "      <td>real snooze A .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8540</th>\n",
              "      <td>2</td>\n",
              "      <td>No surprises .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8541</th>\n",
              "      <td>4</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8542</th>\n",
              "      <td>1</td>\n",
              "      <td>but fans walked out muttering words like `` ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8543</th>\n",
              "      <td>2</td>\n",
              "      <td>In zero case . this</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25632 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text\n",
              "0         4  The Rock is destined to be the 21st Century 's...\n",
              "1         5  The gorgeously elaborate continuation of `` Th...\n",
              "2         4  Singer/composer Bryan Adams contributes a slew...\n",
              "3         3  You 'd think by now America would have had eno...\n",
              "4         4               Yet the act is still charming here .\n",
              "...     ...                                                ...\n",
              "8539      1                                    real snooze A .\n",
              "8540      2                                     No surprises .\n",
              "8541      4  We 've seen the hippie-turned-yuppie plot befo...\n",
              "8542      1  but fans walked out muttering words like `` ho...\n",
              "8543      2                                In zero case . this\n",
              "\n",
              "[25632 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTcTKBB2eBUY",
        "outputId": "c2b8ac63-944e-4cf5-8939-7e2a26eb7971"
      },
      "source": [
        "df_final[\"len\"] = df_final['text'].apply(len)\n",
        "df_final = df_final[df_final.len > 2]\n",
        "df_final.drop_duplicates(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "totgp76wfQYZ"
      },
      "source": [
        "df_final = df_final[[\"label\",\"text\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "228OWvxIhT4U"
      },
      "source": [
        "df_final.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fdn91_GCdXj"
      },
      "source": [
        "df_final = df_final[[\"label\",\"text\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeCBOEHGzN1g"
      },
      "source": [
        "df_final.to_csv(\"df_final_train.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFvxJAkr8Inp"
      },
      "source": [
        "#Test Data\n",
        "import pandas as pd\n",
        "df_test = pd.read_csv(\"sst_test.csv\",delimiter=\"\\t\",names = [\"label\",\"text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7waZmvb68Icg"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# ax = df_test['label'].value_counts(sort=True).plot(kind='barh')\n",
        "# ax.set_xlabel(\"Number of Samples in training Set\")\n",
        "# ax.set_ylabel(\"Label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDIyapAa6Pjr"
      },
      "source": [
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kqZx2hG6e4Q",
        "outputId": "99ae4ad9-8099-4d7a-a5c4-2450ba4ee044"
      },
      "source": [
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1fc11648b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPi_ImgAmcPl",
        "outputId": "ab608097-c388-47fd-f609-7a1ec133f55a"
      },
      "source": [
        "import re \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation \n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt') \n",
        "def cleanup_text(texts):\n",
        "    cleaned_text = []\n",
        "    for text in texts:\n",
        "        # remove punctuation\n",
        "        text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
        "        # remove multiple spaces\n",
        "        text = re.sub(r' +', ' ', text)\n",
        "        # remove newline\n",
        "        text = re.sub(r'\\n', ' ', text)\n",
        "        text = str(text).lower()\n",
        "        text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text) # remove URLs\n",
        "        text = re.sub('@[^\\s]+', 'ATUSER', text) # remove usernames\n",
        "        text = re.sub(r'#([^\\s]+)', r'\\1', text) # remove the # in #hashtag\n",
        "        text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove # and numbers\n",
        "        cleaned_text.append(text)\n",
        "    return cleaned_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db3eiDVx6mKf"
      },
      "source": [
        "Text = torchtext.legacy.data.Field(preprocessing=cleanup_text, sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-by1zHIV7LPI"
      },
      "source": [
        "fields = [('label', Label),('text', Text)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi16azy9tlWp"
      },
      "source": [
        "train_ds, valid_ds, test_ds = data.TabularDataset.splits(\n",
        "  path = '.',\n",
        "  train = 'df_final_train.csv',\n",
        "  validation = 'sst_dev.csv',\n",
        "  test = 'sst_test.csv',\n",
        "  format = 'csv',\n",
        "  fields = fields,\n",
        "  skip_header=True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k83NRHAV4Kfb",
        "outputId": "58b94ee0-7fa4-46a5-9090-6a994588a040"
      },
      "source": [
        "print(vars(train_ds[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'label': '4', 'text': ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', ' s', 'new', ' ', ' ', 'conan', ' ', 'and', 'that', 'he', ' s', 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ' ', 'jean', ' ', 'claud', 'van', 'damme', 'or', 'steven', 'segal', ' ']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91fhtSKS8y3T",
        "outputId": "42e57132-42b7-4fe4-bff7-aeb1087d4412"
      },
      "source": [
        "len(train_ds), len(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24885, 2210)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_K23gxx84-K"
      },
      "source": [
        "Text.build_vocab(train_ds,max_size=5000)\n",
        "Label.build_vocab(train_ds)\n",
        "vocab_size = len(Text.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCPG8VrE9MKq",
        "outputId": "c8ec6bbb-124b-4349-a726-f04fea14b1e8"
      },
      "source": [
        "print('Size of input vocab : ', len(Text.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Text.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  5002\n",
            "Size of label vocab :  5\n",
            "Top 10 words appreared repeatedly : [(' ', 60319), ('the', 20334), ('a', 14666), ('and', 12478), ('of', 12357), ('to', 8527), ('is', 7091), (' s', 7058), ('it', 6737), ('that', 5411)]\n",
            "Labels :  defaultdict(None, {'4': 0, '2': 1, '3': 2, '5': 3, '1': 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBmMQQcX9SZk"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJyulXA9sEr"
      },
      "source": [
        "train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train_ds, test_ds), batch_size = 16, \n",
        "                                                            sort_key = lambda x: len(x.text),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_NVSpoV-Uaj"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Text.vocab.stoi, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4Z--gBjNE17"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim1, hidden_dim2, output_dim, n_layers,\n",
        "                 bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.encoder = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim1,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=bidirectional,\n",
        "                            batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim1*2 , hidden_dim2)\n",
        "        self.fc2 = nn.Linear(hidden_dim2, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded = self.embedding(text)\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "\n",
        "        cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        rel = self.relu(cat)\n",
        "        dense1 = self.fc1(cat)\n",
        "        drop = self.dropout(dense1)\n",
        "        preds = self.fc2(drop)\n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(preds, dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkraYZgYNGN7"
      },
      "source": [
        "lr = 1e-4\n",
        "batch_size = 16\n",
        "embedding_dim = 512\n",
        "dropout_keep_prob = 0.5\n",
        "seed = 42\n",
        "output_dim = 5\n",
        "hidden_dim1 = 256\n",
        "hidden_dim2 = 128\n",
        "n_layers = 2  # LSTM layers\n",
        "bidirectional = True \n",
        "size_of_vocab = len(Text.vocab)\n",
        "model = LSTM(size_of_vocab, embedding_dim, hidden_dim1, hidden_dim2, output_dim, n_layers, bidirectional, dropout_keep_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRextCcAASGO",
        "outputId": "9ca8c4b2-89c5-41ea-fa3b-53516bd84ac9"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM(\n",
            "  (embedding): Embedding(5002, 512)\n",
            "  (encoder): LSTM(512, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=5, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "The model has 5,781,253 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPK6b19HATLm"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8t9iWwqAify"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        text, text_lengths = batch.text\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "        predictions = model(text, text_lengths).squeeze()\n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBXHd5JAuX-"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7UPwN0KAvVq",
        "outputId": "392aeccf-e75c-4777-c74f-84ad0d97bf24"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.540 | Train Acc: 33.60%\n",
            "\t Val. Loss: 1.530 |  Val. Acc: 35.52% \n",
            "\n",
            "\tTrain Loss: 1.415 | Train Acc: 47.84%\n",
            "\t Val. Loss: 1.502 |  Val. Acc: 37.23% \n",
            "\n",
            "\tTrain Loss: 1.318 | Train Acc: 58.44%\n",
            "\t Val. Loss: 1.511 |  Val. Acc: 37.77% \n",
            "\n",
            "\tTrain Loss: 1.236 | Train Acc: 66.92%\n",
            "\t Val. Loss: 1.512 |  Val. Acc: 37.50% \n",
            "\n",
            "\tTrain Loss: 1.178 | Train Acc: 72.79%\n",
            "\t Val. Loss: 1.513 |  Val. Acc: 37.68% \n",
            "\n",
            "\tTrain Loss: 1.130 | Train Acc: 77.64%\n",
            "\t Val. Loss: 1.518 |  Val. Acc: 37.10% \n",
            "\n",
            "\tTrain Loss: 1.102 | Train Acc: 80.35%\n",
            "\t Val. Loss: 1.509 |  Val. Acc: 38.22% \n",
            "\n",
            "\tTrain Loss: 1.078 | Train Acc: 82.71%\n",
            "\t Val. Loss: 1.526 |  Val. Acc: 36.87% \n",
            "\n",
            "\tTrain Loss: 1.061 | Train Acc: 84.51%\n",
            "\t Val. Loss: 1.522 |  Val. Acc: 37.05% \n",
            "\n",
            "\tTrain Loss: 1.048 | Train Acc: 85.68%\n",
            "\t Val. Loss: 1.520 |  Val. Acc: 37.41% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCGxks4AxT3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XU_DlC1HY5T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}